{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed-Neural-Network to solve Partial Differential Equation\n",
    "- Aim: To compare performance with Finite-Volume Implicit Numerical Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with traditional methods: -\n",
    "- High computational costs\n",
    "- Boundary problems\n",
    "- Computational costs for mesh generation\n",
    "- Scaling for complex systems\n",
    "- Numerical Instability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of Neural Networks: -\n",
    "- Adaptive learning- hence, may approximate function more efficiently\n",
    "- Auto Differentiation- Key aspect of NN (gradient descent) that can also be applied to PDE solving for precise derivative calculations more efficienty\n",
    "- PINNs use a cumulative loss function that ensures the computed answer complies with both- the data and the laws of physics that govern the PDE \n",
    "- Hence, appear to be more accurate approximations by embedding physics\n",
    "- Consequently, should be more data efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risks to explore: -\n",
    "- Training complexity\n",
    "- Overfitting\n",
    "- Numerical Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers, models, initializers\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "import numpy as npx\n",
    "\n",
    "import math as m \n",
    "\n",
    "# Data type\n",
    "DTYPE='float32'\n",
    "tf.keras.backend.set_floatx(DTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Setup: -\n",
    "### Idea: -\n",
    "\n",
    "We construct a Neural Network approximation,\n",
    "$$\n",
    "u_\\theta(t, x) \\approx u(t,x),\n",
    "$$\n",
    "\n",
    "where $u_\\theta : [0, T] \\times \\mathcal{D} \\to \\mathbb{R}$ denotes a function approximated by a neural network with parameters $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Burger's Equation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\partial_t u + u.\\partial_x u - v.\\partial_{xx} u &= 0, \\quad && \\quad (t, x) \\in (0, 1] \\times (-1, 1);\\\\\n",
    "   u(0, x) &= -\\sin(\\pi.x), \\quad && \\quad x \\in [-1,1];\\\\\n",
    "   u(t, -1) &= u(t, 1) = 0, \\quad && \\quad t \\in (0,1];\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "alpha = 1  # v\n",
    "pi = tf.constant(m.pi)\n",
    "\n",
    "# Initial condition\n",
    "def fun_u_0(x):\n",
    "    return -tf.sin(pi*x)    # u_0(x) = sin(pi.x)\n",
    "\n",
    "# PDE residual using TensorFlow AutoDiff\n",
    "def pde_residual(model, t, x):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([t, x])\n",
    "        u = model(tf.concat([t, x], axis=1))\n",
    "        u_t = tape.gradient(u, t)\n",
    "    u_x = tape.gradient(u, x)\n",
    "    u_xx = tape.gradient(u_x, x)\n",
    "    del tape\n",
    "\n",
    "    return u_t - alpha*u_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.scatter(t_0, x_0, c=u_0, marker='X', vmin=-1, vmax=1)\n",
    "# plt.scatter(t_b, x_b, c=u_b, marker='X', vmin=-1, vmax=1)\n",
    "# plt.scatter(t_r, x_r, c='r', marker='.', alpha=0.1)\n",
    "\n",
    "# plt.xlabel('$t$'); plt.ylabel('$x$')\n",
    "# plt.title('Mesh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "activation = 'tanh'\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#PINN model\n",
    "class PINNModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        \"\"\"\n",
    "        Build a PINN model for Burgers' equation with input shape (t, x) and output shape u(t, x).\n",
    "\n",
    "        Args:\n",
    "            hp: HyperParameter object to find best parameters\n",
    "            A: activation function in hidden layers.\n",
    "\n",
    "        Returns:\n",
    "            Network model\n",
    "        \"\"\"\n",
    "\n",
    "        model = models.Sequential()\n",
    "\n",
    "        # 2 neuron input layer: (t, x)\n",
    "        model.add(layers.InputLayer(input_shape=(2,)))  \n",
    "        # Hidden layers\n",
    "        for i in range(hp.Int('num_layers', 1, 32)):\n",
    "            model.add(layers.Dense(\n",
    "                units= hp.Int('units_' + str(i), 32, 512, step=32),\n",
    "                activation = activation,\n",
    "                kernel_initializer = initializers.GlorotUniform()\n",
    "            ))\n",
    "        # 1 neuron output layer: u(t, x)\n",
    "        model.add(layers.Dense(1, activation=None))  \n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=lambda y_true, y_pred: pinn_loss(model, t, x, t_bc, x_bc, u_bc)\n",
    "        ) \n",
    "\n",
    "        return model\n",
    "\n",
    "# Loss function that enforces physical lalws (PDE and boundary conditions)\n",
    "def pinn_loss(model, t, x, t_bc, x_bc, u_bc):\n",
    "    pde_loss = tf.reduce_mean(tf.square(pde_residual(model, t, x)))\n",
    "    bc_loss = tf.reduce_mean(tf.square(model(tf.concat([t_bc, x_bc], axis=1)) - u_bc))\n",
    "    \n",
    "    return pde_loss + bc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom training step\n",
    "@tf.function\n",
    "def train_step(model, t, x, t_bc, x_bc, u_bc):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = pinn_loss(model, t, x, t_bc, x_bc, u_bc)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Synthetic training data\n",
    "def generate_data(num_samples):\n",
    "    t = tf.random.uniform((num_samples, 1), 0, 1)\n",
    "    x = tf.random.uniform((num_samples, 1), 0, 1)\n",
    "    #u_true = tf.sin(np.pi * x) * tf.exp(-np.pi**2 * t)\n",
    "    return t, x\n",
    "\n",
    "# Generate boundary condition data\n",
    "def generate_boundary_data(num_samples):\n",
    "    t_bc = tf.random.uniform((num_samples, 1), 0, 1)\n",
    "    x_bc = tf.concat([tf.zeros((num_samples // 2, 1)), tf.ones((num_samples // 2, 1))], axis=0)\n",
    "    u_bc = tf.concat([tf.zeros((num_samples // 2, 1)), tf.zeros((num_samples // 2, 1))], axis=0)\n",
    "    return t_bc, x_bc, u_bc\n",
    "\n",
    "# Data\n",
    "num_samples = 1000\n",
    "t_train, x_train = generate_data(num_samples)\n",
    "t_bc, x_bc, u_bc = generate_boundary_data(num_samples // 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from pinn_tuning\\pinn_heat_equation\\tuner0.json\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "13                |22                |num_layers\n",
      "352               |288               |units_0\n",
      "32                |32                |units_1\n",
      "224               |32                |units_2\n",
      "192               |32                |units_3\n",
      "352               |32                |units_4\n",
      "384               |32                |units_5\n",
      "256               |32                |units_6\n",
      "320               |32                |units_7\n",
      "32                |32                |units_8\n",
      "352               |32                |units_9\n",
      "160               |32                |units_10\n",
      "128               |32                |units_11\n",
      "352               |32                |units_12\n",
      "416               |32                |units_13\n",
      "160               |32                |units_14\n",
      "160               |32                |units_15\n",
      "480               |32                |units_16\n",
      "384               |32                |units_17\n",
      "64                |32                |units_18\n",
      "32                |32                |units_19\n",
      "352               |32                |units_20\n",
      "512               |32                |units_21\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (None, 1)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n",
      "  • training=True\n",
      "  • mask=None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (None, 1)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n  • training=True\n  • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m tuner \u001b[38;5;241m=\u001b[39m RandomSearch(\n\u001b[0;32m      4\u001b[0m     hypermodel,\n\u001b[0;32m      5\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinn_heat_equation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Perform the search\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Retrieve the best model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:339\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[0;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[1;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[0;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\oracle.py:588\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\oracle.py:545\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    543\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    549\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\89\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (None, 1)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n  • training=True\n  • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "hypermodel = PINNModel()\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    directory='pinn_tuning',\n",
    "    project_name='pinn_heat_equation'\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "tuner.search(t_train, None, epochs=100, validation_data=(t_train, None))\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the best model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_step(\u001b[43mbest_model\u001b[49m, t_train, x_train, t_bc, x_bc, u_bc)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the best model\n",
    "for epoch in range(1000):\n",
    "    loss = train_step(best_model, t_train, x_train, t_bc, x_bc, u_bc)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulation Parameters\n",
    "\n",
    "# Number of points\n",
    "N_0 = 64\n",
    "N_b = 64\n",
    "N_r = 8320\n",
    "\n",
    "\n",
    "# Mesh\n",
    "tmin, tmax = 0., 1.\n",
    "xmin, xmax = -1., 1.\n",
    "\n",
    "\n",
    "# Lower bounds\n",
    "lb = tf.constant([tmin, xmin], dtype=DTYPE)\n",
    "# Upper bounds\n",
    "ub = tf.constant([tmax, xmax], dtype=DTYPE)\n",
    "\n",
    "\n",
    "# Draw uniform sample points for initial boundary data\n",
    "tf.random.set_seed(123)     #seed for reproducible results\n",
    "t_0 = tf.ones((N_0,1), dtype=DTYPE)*lb[0]\n",
    "x_0 = tf.random.uniform((N_0,1), lb[1], ub[1], dtype=DTYPE)\n",
    "X_0 = tf.concat([t_0, x_0], axis=1)\n",
    "\n",
    "\n",
    "# Boundary data\n",
    "t_b = tf.random.uniform((N_b,1), lb[0], ub[0], dtype=DTYPE)\n",
    "x_b = lb[1] + (ub[1] - lb[1]) * tf.keras.backend.random_bernoulli((N_b,1), 0.5, dtype=DTYPE)\n",
    "X_b = tf.concat([t_b, x_b], axis=1)\n",
    "\n",
    "X_data = [X_0, X_b]\n",
    "\n",
    "# Draw uniformly sampled collocation points\n",
    "t_r = tf.random.uniform((N_r,1), lb[0], ub[0], dtype=DTYPE)\n",
    "x_r = tf.random.uniform((N_r,1), lb[1], ub[1], dtype=DTYPE)\n",
    "X_r = tf.concat([t_r, x_r], axis=1)\n",
    "\n",
    "# u_0 = fun_u_0(x_0)          # Initial data\n",
    "# u_b = fun_u_b(t_b, x_b)     # Boundary data\n",
    "\n",
    "# u_data = [u_0, u_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh\n",
    "- collocation points: red circles\n",
    "- boundary and initial conditions: cross marks (colour indicates value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m(tf\u001b[38;5;241m.\u001b[39mconcat([t_train, x_train], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, pinn_loss(best_model, t_train, x_train, t_bc, x_bc, u_bc)\u001b[38;5;241m.\u001b[39mnumpy(), u_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "u_pred = best_model(tf.concat([t_train, x_train], axis=1))\n",
    "print(\"Final loss:\", pinn_loss(best_model, t_train, x_train, t_bc, x_bc, u_bc).numpy(), u_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
